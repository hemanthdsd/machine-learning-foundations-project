{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73558a5d-c3ca-4a6c-bdb8-ab6dec07d13d",
   "metadata": {},
   "source": [
    "<b>IS41070 Machine Learning Foundations Project<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de4426-9fdd-438f-bc6d-e7976986aab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33e86d0e-d5b5-4822-bf12-42f8d82a8537",
   "metadata": {},
   "source": [
    "<b>Install Necessary Packages<b>\n",
    "\n",
    "In this section, we will install the necessary packages for our project. These include:\n",
    "- `pandas` for data manipulation and analysis\n",
    "- `numpy` for numerical operations\n",
    "- `seaborn` for statistical data visualization\n",
    "- `nltk` for natural language processing\n",
    "- `matplotlib` for plotting and visualization\n",
    "- `wordcloud` for generating word clouds from text data\n",
    "- `scikit-learn` for machine learning algorithms and tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a9635-91da-4765-afd5-0b3eb2bdebcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install pandas for data manipulation and analysis\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d126203c-62b8-4b40-8140-d8d5e0f2eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install numpy for numerical operations\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65cd3be-c253-460c-bb4b-a785ab88d8cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install seaborn for statistical data visualization\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236fa46-43f6-47eb-a900-567a1f28250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install nltk for natural language processing\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3881f9d-2358-41ee-a453-2b42efa2a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install matplotlib for plotting and visualization\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f856dfd-e504-4ab1-9106-6d8932b80483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install wordcloud for generating word clouds from text data\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5bd656-7a8f-4f66-9dc5-ae1b6a9ec4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install scikit-learn for machine learning algorithms and tools\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692a288-9eed-4e32-88d2-e9069edce13f",
   "metadata": {},
   "source": [
    "<b> Data Understanding & Exploration<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf7a01-68bd-47cb-bdcd-fd1bd2233d8c",
   "metadata": {},
   "source": [
    "Loading the Dataset, we will load the dataset provided for the project. This dataset contains news articles and their corresponding categories. We will use `pandas` to load the data and perform initial exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da28033a-1461-429f-bb3d-2e73a026769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Import the pandas library for data manipulation\n",
    "\n",
    "news_data= pd.read_csv('22.csv')# Load the dataset from the CSV file into a DataFrame\n",
    "\n",
    "news_data.head() # Display the first few rows of the DataFrame to check the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d77d9d2-7525-4520-bf74-d09080d336e0",
   "metadata": {},
   "source": [
    "Data Exploration\n",
    "\n",
    "we will perform an initial exploration of the dataset. This includes:\n",
    "- Checking the basic structure of the dataset\n",
    "- Exploring the distribution of categories\n",
    "- Analyzing the text data (most common terms, sentence lengths, etc.)\n",
    "- Checking for missing values and outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfafb04-b43b-4de3-ab88-cc6dc74479f9",
   "metadata": {},
   "source": [
    "Basic description of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f28f2-2b8d-4354-adce-52ca5d0deec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data.info() # Display information about the DataFrame, such as the number of rows and columns, data types, and non-null counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3162cb2-6cd6-4491-9c19-4cd6aa23983e",
   "metadata": {},
   "source": [
    "Lets remane the First column to \"S.no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a54ba99-0095-4bd8-9c8e-48c9764f2662",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data.rename(columns={'Unnamed: 0': 'S.no'}, inplace=True) # Rename the column 'Unnamed: 0' to 'S.no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e07a3-8932-48de-a994-8bbf9bae6127",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data.head() # Display the first few rows of the DataFrame to verify the change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c155ad3-7d43-468c-a466-67726f9b04ee",
   "metadata": {},
   "source": [
    "Distribution of Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316e0e8-f007-45f0-8c6b-ba1149135c4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "category_distribution = news_data['category'].value_counts() # Display the distribution of categories\n",
    "print(category_distribution)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt # Plot the distribution of categories\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=news_data, x='category', order=category_distribution.index)\n",
    "plt.title('Distribution of Categories')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153d7a8-c847-4dc9-bb2a-8ec5c0ee3a9c",
   "metadata": {},
   "source": [
    "The dataset has a significant imbalance, with 5984 instances of \"POLITICS\" compared to 1996 instances of \"CRIME.\" This disparity can cause the model to become biased towards predicting \"POLITICS\" more frequently. As a result, the model's predictions may be skewed, favoring \"POLITICS\" and leading to inaccurate results. Additionally, the model's sensitivity to the \"CRIME\" category will be reduced, with lower recall and precision, causing many true \"CRIME\" instances to be missed or misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24292633-5421-475b-89a9-da1e93b08d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data.describe(include='all') # Display summary statistics of the DataFrame, including count, unique values, top values, and frequency for categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c062dbe-c413-40a1-86a3-90ccdd04f6f2",
   "metadata": {},
   "source": [
    "checking for missing values\n",
    "\n",
    "Its always important to check the data for completeness( for higher accuracy of the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9466575-cd42-4038-9456-7e5cf92983fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = news_data.isnull().sum() # Check for missing values \n",
    "missing_values  # Display the count of missing values for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14032cf7-eae7-4d09-9b3e-10470b7110d9",
   "metadata": {},
   "source": [
    "We can see that several columns have missing values, but our primary concern is the category column. This column plays a crucial role in training the model it determines the classification of each article into specific categories, such as POLITICS or CRIME based on content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cb219f-c0da-4f94-92dc-46016754515e",
   "metadata": {},
   "source": [
    "We will remove those 20 rows where we have no categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2833d-e195-4a19-ab40-ab48e3dea32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_cleaned = news_data.dropna(subset=['category']) # Drop rows where 'category' is NaN\n",
    "\n",
    "# Check the result\n",
    "missing_values_after = news_data_cleaned.isnull().sum()\n",
    "missing_values_after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743cdada-1cd4-45a6-ab7d-e00964af6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_cleaned.describe(include='all') # Display summary statistics of the DataFrame, including count, unique values, top values, and frequency for categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5c3eb7-8d53-4d7a-bbab-807b21cb4de1",
   "metadata": {},
   "source": [
    "<b>Data Analysis<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a530df2c-b96d-42bd-ba44-1723f5d36ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "nltk.download('punkt') # Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c2d18-1a72-4f76-95d6-861c18d9d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_copy = news_data_cleaned.copy() # Create a copy of the DataFrame to avoid modifying the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2194ad4-c6ec-4216-902b-fd15858e54fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_copy['headline'] = news_data_copy['headline'].fillna('')\n",
    "\n",
    "news_data_copy['short_description'] = news_data_copy['short_description'].fillna('')  # Fill missing values in the 'short_description' column with empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767c7c8-2248-4ebf-9742-b33340e9115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that there are no more missing values\n",
    "missing_values_after = news_data_copy.isnull().sum()\n",
    "print(missing_values_after)  # Display the count of missing values for each column to confirm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa8b05b-932f-4290-9464-3696c63eb2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() # Initialize the WordNetLemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def preprocess_text(text):  # Define a function to preprocess text (tokenize, remove stopwords, and lemmatize)\n",
    "    tokens = word_tokenize(text.lower())  # Tokenize and convert to lowercase\n",
    "    filtered_tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalpha() and word not in stop_words]  # Remove stopwords and lemmatize\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e0ce8-2cd0-47ad-a937-2bd467cde350",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_copy['text'] = news_data_copy['headline'] + ' ' + news_data_copy['short_description'] # Combine the 'headline' and 'short_description' into a single text column for vectorization\n",
    "\n",
    "\n",
    "news_data_copy['processed_text'] = news_data_copy['text'].apply(preprocess_text) # Apply the preprocessing function to the 'text' column\n",
    "\n",
    "\n",
    "news_data_copy[['text', 'processed_text']].head() # Display the first few rows of the DataFrame to verify the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d195da5-f12a-4570-9956-3793a9479471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from collections import Counter  # To count word frequencies\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "import seaborn as sns  # For more advanced plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1b7df-26cc-4806-a386-d686b047d171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_most_common_terms(data, category, num_terms=20): #Plot the most common terms in a specific category.\n",
    " \n",
    "    category_data = data[data['category'] == category] # Filter data for the specific category\n",
    "    \n",
    "    all_text = ' '.join(category_data['processed_text'])  # Combine all processed text into a single string\n",
    "    \n",
    "    word_counts = Counter(all_text.split())  # Tokenize the combined text and count the terms\n",
    "    \n",
    "    common_terms = word_counts.most_common(num_terms)    # Get the most common terms\n",
    "    \n",
    "    common_terms_df = pd.DataFrame(common_terms, columns=['term', 'count']) # Create a DataFrame for plotting\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))   # Plot the most common terms using seaborn's barplot\n",
    "    sns.barplot(x='count', y='term', data=common_terms_df)\n",
    "    plt.title(f'Most Common Terms in {category}')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Term')\n",
    "    plt.show()\n",
    "\n",
    "for category in news_data_copy['category'].unique(): # Plot the most common terms for each category\n",
    "    plot_most_common_terms(news_data_copy, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea085f7-6a6f-4c3f-9c46-48f65aa6b7b5",
   "metadata": {},
   "source": [
    "Key Observations:\n",
    "Politics:\n",
    "- \"Trump\" is the most frequent term by a large margin.\n",
    "- Political Figures: Frequent mentions of \"donald,\" \"clinton,\" \"obama,\" and \"hillary.\"\n",
    "- Political Terms: Common words include \"president,\" \"republican,\" \"state,\" and \"gop.\"\n",
    "\n",
    "Crime:\n",
    "- \"Police\" is the most common term.\n",
    "- High frequency of \"man,\" \"shooting,\" \"suspect,\" \"officer,\" and \"killed.\"\n",
    "- Common terms include \"death,\" \"found,\" \"shot,\" \"accused,\" and \"arrested.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dce6215-5ba3-44df-bc39-c5df29d61629",
   "metadata": {},
   "source": [
    "we can further analyze other features in the dataset and their relationship with the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed53cc1-1e12-4ad1-840c-fb2b4349b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_copy['text_length'] = news_data_copy['processed_text'].apply(len) # Add a column for the length of the processed text\n",
    "\n",
    "plt.figure(figsize=(12, 6)) # Plot the distribution of text length for each category\n",
    "sns.histplot(data=news_data_copy, x='text_length', hue='category', multiple='stack', kde=True)\n",
    "plt.title('Distribution of Text Length by Category')\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f21f2-0fa0-43de-aa9e-83a9dd91475e",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- \"POLITICS\" category shows an approximately normal distribution with a peak around 100 characters.\n",
    "- \"CRIME\" category has a similar distribution but with lower frequency.\n",
    "- High concentration of articles in both categories within the 50 to 150 character range.\n",
    "- \"POLITICS\" articles exhibit a wider spread, some exceeding 500 characters.\n",
    "- \"CRIME\" articles show less variation, with fewer long articles.\n",
    "- \"POLITICS\" articles are more frequent overall compared to \"CRIME\" articles.\n",
    "- Some outliers in the \"POLITICS\" category have text lengths greater than 400 characters.\n",
    "- Political articles are generally longer and more frequent than crime-related articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40641a46-8425-4606-b378-1ca55a76d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f48e26-4262-4690-bc63-fe6fbb1e9f43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_data_copy = news_data_copy[(news_data_copy['text_length'] <= 450) & (news_data_copy['text_length'] >= 50)] # Remove outliers based on text length\n",
    "\n",
    "# Verify the cleaning process\n",
    "news_data_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b67e5cd-9c50-46db-a073-2d4155fe7548",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_copy['text_length'] = news_data_copy['processed_text'].apply(len) # Add a column for the length of the processed text\n",
    "\n",
    "plt.figure(figsize=(12, 6)) # Plot the distribution of text length for each category\n",
    "sns.histplot(data=news_data_copy, x='text_length', hue='category', multiple='stack', kde=True)\n",
    "plt.title('Distribution of Text Length by Category')\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe860a3-c176-4f4a-ab46-b7420a06e2cf",
   "metadata": {},
   "source": [
    "We have removed the outliers and ensured that the total text length (Headline + Short Description) is between 50 and 450 characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a2589-6c00-4844-b9bd-352cc265739f",
   "metadata": {},
   "source": [
    "<b>Data Preparation<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e9f89-7c73-4113-b1c4-dbb797875c48",
   "metadata": {},
   "source": [
    "Since we have noticed a significant imbalance in your dataset, it's crucial to split your data in a way that maintains the distribution of the classes across training, validation, and test sets. An effective approach would be using stratified sampling, which ensures that each subset has approximately the same class distribution as the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca7ac6c-568e-425c-8b9d-e6b02f0d828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # Import train_test_split for splitting the dataset\n",
    "\n",
    "# First, split the data into training (80%) and testing sets (20%)\n",
    "train_df, test_df = train_test_split(news_data_copy, test_size=0.2, random_state=42, stratify=news_data_copy['category'])\n",
    "\n",
    "# Then, split the training set further into training (60% of original data) and validation sets (20% of original data)\n",
    "train_df, valid_df = train_test_split(train_df, test_size=0.25, random_state=42, stratify=train_df['category'])\n",
    "\n",
    "# Save the training, validation, and testing sets to CSV files\n",
    "train_df.to_csv('train.csv', index=False)\n",
    "valid_df.to_csv('valid.csv', index=False)\n",
    "test_df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cb4742-6725-4e29-ac0a-4e32f5f77867",
   "metadata": {},
   "source": [
    "Verify and check the distribution of the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4426f-5763-411c-a564-0e3b5ca3a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the splits\n",
    "print(\"Training set size:\", train_df.shape[0])\n",
    "print(\"Validation set size:\", valid_df.shape[0])\n",
    "print(\"Testing set size:\", test_df.shape[0])\n",
    "\n",
    "# Check the distribution of categories in each set\n",
    "print(\"\\nTraining set category distribution:\\n\", train_df['category'].value_counts())\n",
    "print(\"\\nValidation set category distribution:\\n\", valid_df['category'].value_counts())\n",
    "print(\"\\nTesting set category distribution:\\n\", test_df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b6c7d-2da1-4963-b3f6-66b2385880f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the training data to check the loaded data\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7b4807-3c44-4e1a-b2f3-b24cfa6a9165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the validation data to check the loaded data\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09528a8-2219-4847-9ffd-d7e2ab9039e1",
   "metadata": {},
   "source": [
    "Vectorizing the Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8173d1d-54f6-4f0d-a756-7692da03d56e",
   "metadata": {},
   "source": [
    "We will use the TF-IDF vectorizer to convert the text data into numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b291c80-3832-46de-a78b-18f5305a15ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Import TfidfVectorizer for converting text to numeric features\n",
    "\n",
    "# Combine preprocessing and TF-IDF vectorization in a single step\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,  # Convert all characters to lowercase\n",
    "    stop_words='english',  # Remove English stopwords\n",
    "    max_features=5000  # Consider only the top 5000 words by frequency\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_df['processed_text']) # Fit the vectorizer on the training data and transform the text data into TF-IDF features\n",
    "X_valid = vectorizer.transform(valid_df['processed_text'])\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape) # Display the shape of the resulting feature matrices\n",
    "print(\"Shape of X_valid:\", X_valid.shape)\n",
    "\n",
    "y_train = train_df['category'] # Extract the labels (categories) from the training and validation data\n",
    "y_valid = valid_df['category']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78107230-1d7c-4ce2-9d22-06658bcd458f",
   "metadata": {},
   "source": [
    "<b>Building and Evaluating Machine Learning Models<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83003eca-1431-425c-8460-975de6c218ed",
   "metadata": {},
   "source": [
    "we will use Logistic Regression and Support Vector Machine (SVM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef6aea-1030-43ab-a4d6-6df2bfaa7aeb",
   "metadata": {},
   "source": [
    "- Logistic Regression was chosen because of its simplicity, speed, and probabilistic results.\n",
    "- SVM was chosen for its efficacy in high-dimensional text data and resistance to overfitting.\n",
    "\n",
    "  These models work together to achieve balanced performance and interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be63c16-5767-4c5d-aeb0-7c1f32e66444",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "\n",
    "We will start with a simple Logistic Regression model to set a baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aebae3-6e4b-4ae4-a81d-4c9bd35f35db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Initialize the model\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_log_reg = log_reg.predict(X_valid)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "print(\"Logistic Regression Performance on Validation Set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_valid, y_pred_log_reg)}\")\n",
    "print(classification_report(y_valid, y_pred_log_reg))\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_valid, y_pred_log_reg)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a7940-119b-4d59-9aa8-c04011c6f020",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM)\n",
    "\n",
    "we will build a Support Vector Machine classifier to further test our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd24e47-9216-4435-ad9e-24a057c6c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the model\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_svm = svm_clf.predict(X_valid)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "print(\"Support Vector Machine Performance on Validation Set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_valid, y_pred_svm)}\")\n",
    "print(classification_report(y_valid, y_pred_svm))\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_valid, y_pred_svm)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ca8266-1702-4594-9732-512924831099",
   "metadata": {},
   "source": [
    "<b>Building Our Own Deep Learning Model<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd932b4b-ba25-4c14-8651-75ffe88e7312",
   "metadata": {},
   "source": [
    "We will use TensorFlow/Keras to create a simple LSTM model(type of recurrent neural network (RNN)).\n",
    "\n",
    "we are using the Long Short-term memory(LSTM) model as they can learn, process, and classify sequential data because these networks can learn long-term dependencies between time steps of data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab027aab-723a-4646-b565-8ac36e90876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f38f00-c549-4dfe-8266-f549507522cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Combine text columns and preprocess the data\n",
    "train_texts = train_df['processed_text']\n",
    "valid_texts = valid_df['processed_text']\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "valid_sequences = tokenizer.texts_to_sequences(valid_texts)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=500, padding='post', truncating='post')\n",
    "valid_padded = pad_sequences(valid_sequences, maxlen=500, padding='post', truncating='post')\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_df['category'])\n",
    "y_valid = le.transform(valid_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03940cb2-2d82-4bdf-9bed-9d6c2a0d16c0",
   "metadata": {},
   "source": [
    "Build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045a4cfc-cb05-4c3e-bc00-a5901a1d133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(10000, 64, input_length=450),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_padded, y_train, epochs=10, validation_data=(valid_padded, y_valid), batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a244e6-c24b-4f82-8e7e-b4b19388faf8",
   "metadata": {},
   "source": [
    "Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14628105-8aeb-4a14-867d-d5c250b89710",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(valid_padded, y_valid)\n",
    "print(f'Validation Accuracy: {accuracy}')\n",
    "print(f'Validation Loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d856e-68e4-4d24-83ba-2ee5139157c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy and loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12247534-1d83-4fa9-8d84-1d851ef26f16",
   "metadata": {},
   "source": [
    "<b>EVALUATION<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e7f23-aa2a-4e8b-80fc-15f89154bad9",
   "metadata": {},
   "source": [
    "<b>Error Analysis<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf48575b-7ccd-451a-ad37-a2eb07b416f1",
   "metadata": {},
   "source": [
    "Own Deep Learning MOdel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59399162-f141-47ce-a2b3-8f0a42c70de2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict the validation data\n",
    "y_pred = (model.predict(valid_padded) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Generate a classification report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc9ec9-95e5-4e6c-8790-a063c7c25b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Determine the mapping based on known class distribution\n",
    "politics_class = 1  # Larger class (5528 instances)\n",
    "crime_class = 0     # Smaller class (1697 instances)\n",
    "\n",
    "print(f\"Class {crime_class} corresponds to CRIME.\")\n",
    "print(f\"Class {politics_class} corresponds to POLITICS.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c518cd18-ae6a-49b6-b67b-8aef3b4c0408",
   "metadata": {},
   "source": [
    "Based on the above classification Report\n",
    "\n",
    "Class 0: CRIME\n",
    "\n",
    "- Precision: 0.00 - The model never correctly predicted class 0.\n",
    "- Recall: 0.00 - Out of all the actual class 0 instances, the model didn't get any right.\n",
    "- F1-Score: 0.00 - Overall performance for class 0 is very poor.\n",
    "                                      \n",
    "Class 1: POLITICS\n",
    "\n",
    "- Precision: 0.76 - 76% of the time the model predicted class 1 correctly.\n",
    "- Recall: 1.00 - The model identified all actual class 1 instances correctly.\n",
    "- F1-Score: 0.87 - Good performance for class 1.\n",
    "\n",
    "Overall Accuracy: 0.76 - 76% of the total predictions are correct, but this is mostly because the model is good at predicting class 1( due to significant imbalance, with 5984 instances of \"POLITICS\" compared to 1996 instances of \"CRIME.\" )\n",
    "\n",
    "The model is biased towards the majority class (class 1: POLITICS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d9a546-f528-4918-b134-ce6f55232c9a",
   "metadata": {},
   "source": [
    "Logistic Regression & SVM :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a58488b-9a23-4222-91e1-f91198b37c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the model\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_log_reg = log_reg.predict(X_valid)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "print(\"Logistic Regression Performance on Validation Set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_valid, y_pred_log_reg)}\")\n",
    "print(classification_report(y_valid, y_pred_log_reg))\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_valid, y_pred_log_reg)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Initialize the model\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_svm = svm_clf.predict(X_valid)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "print(\"Support Vector Machine Performance on Validation Set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_valid, y_pred_svm)}\")\n",
    "print(classification_report(y_valid, y_pred_svm))\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_valid, y_pred_svm)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b07d1-c379-4f71-9179-8ca5e22e6bf0",
   "metadata": {},
   "source": [
    "From above, It is clearly evident that SVM model have the higher accuarcy over other two models. \n",
    "    \n",
    "Logistic Regression:\n",
    "\n",
    "- High accuracy (~91%) and good performance overall.\n",
    "- Struggles more with identifying CRIME (lower recall of 0.65), indicating many CRIME articles are misclassified as POLITICS.\n",
    "- POLITICS classification is strong (high recall and precision).\n",
    "- Out of 340 CRIME instances, 220 were correctly classified, and 120 were misclassified as POLITICS.\n",
    "- Out of 1105 POLITICS instances, 1090 were correctly classified, and 15 were misclassified as CRIME.\n",
    "\n",
    "Support Vector Machine:\n",
    "\n",
    "- Higher accuracy (~93%) than Logistic Regression.\n",
    "- Better balance in classifying both CRIME and POLITICS.\n",
    "- Improved recall for CRIME (0.79) compared to Logistic Regression, indicating fewer CRIME articles are misclassified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8d9817-ab50-42c8-99e7-5254930e13a2",
   "metadata": {},
   "source": [
    "We will use the F1-score as our major assessment metric. A single measure that balances false positives and false negatives is the F1-score, which is the harmonic mean of precision and recall. This is especially important with imbalanced datasets, when accuracy may not provide a clear view of model performance.\n",
    "\n",
    "Given the imbalance in our dataset (more instances of \"POLITICS\" than \"CRIME\"), the F1-score ensures that our model performs well across both classes rather than just the majority class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1972033-57f0-4acb-915a-a659756200c4",
   "metadata": {},
   "source": [
    "<b>MODEL IMPROVEMENT<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7045f7-eec1-4818-9793-018a90d15737",
   "metadata": {},
   "source": [
    "Logistic Regression Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea17f28-8e27-4cac-a572-99a8b0d4136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Feature Scaling \n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "# Initialize the model with GridSearchCV for hyperparameter tuning\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best estimator after hyperparameter tuning\n",
    "log_reg_best = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_log_reg_best = log_reg_best.predict(X_valid_scaled)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "print(\"Improved Logistic Regression Performance on Validation Set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_valid, y_pred_log_reg_best)}\")\n",
    "print(classification_report(y_valid, y_pred_log_reg_best))\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm_best = confusion_matrix(y_valid, y_pred_log_reg_best)\n",
    "print(\"Confusion Matrix:\\n\", cm_best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0145cd5-7043-4d06-b6ff-d216878fed51",
   "metadata": {},
   "source": [
    "Key Improvements:\n",
    "\n",
    "- Feature Scaling: We standardized the data, ensuring that all features are on the same scale. This allows the Logistic Regression model to learn more successfully since it treats each feature equally.\n",
    "- Hyperparameter Tuning: We utilized GridSearchCV for testing with alternative values for a model parameter (C). This technique assisted us in determining the ideal configuration for the model, hence boosting its performance.\n",
    "\n",
    "performance Comparison:\n",
    "- Accuracy: Increased from 90.7% to 91.1%.\n",
    "- Precision and Recall for Minority Class (0): Improved precision (0.85 vs. 0.94) and recall (0.76 vs. 0.65), leading to a more balanced model.\n",
    "- Confusion Matrix: Fewer false positives (82 vs. 120) and false negatives (46 vs. 15), indicating better prediction quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d674c-909d-41b2-a3aa-2f52056ba781",
   "metadata": {},
   "source": [
    "Support Vector Machine Model(Use Ensemble Approach):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bebe65f-657a-4852-b9d2-10b1c75bb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialize base models\n",
    "lr = LogisticRegression()\n",
    "nb = MultinomialNB()\n",
    "svm = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "# Create an ensemble model\n",
    "ensemble_clf = VotingClassifier(estimators=[\n",
    "    ('lr', lr), ('nb', nb), ('svm', svm)], voting='soft')\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_ensemble = ensemble_clf.predict(X_valid_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Ensemble Model Performance on Validation Set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_valid, y_pred_ensemble)}\")\n",
    "print(classification_report(y_valid, y_pred_ensemble))\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm_ensemble = confusion_matrix(y_valid, y_pred_ensemble)\n",
    "print(\"Confusion Matrix:\\n\", cm_ensemble)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5ae0b0-6bce-4a68-a4f8-214efffae716",
   "metadata": {},
   "source": [
    "Despite a slight decline in overall performance compared to the Support Vector Machine (SVM) model, the current ensemble model demonstrates several positive aspects.\n",
    "\n",
    "Positive Aspects of the Current Ensemble Model:\n",
    "\n",
    "- Improved Recall for Minority Class (0): Increased from 0.79 to 0.80, better at identifying true positives.\n",
    "- Fewer False Positives: Decreased from 73 to 69, indicating improved precision.\n",
    "- Balanced Performance: More balanced across metrics, beneficial when both precision and recall are critical.\n",
    "\n",
    "might perform well, when trained with large data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e145ebe9-d668-4761-89b3-2af1fe65efe0",
   "metadata": {},
   "source": [
    "- Now, we are left with an Improved Logistic Regression Model and Ensemble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c839f6e-7521-41a8-a1a7-407e0b78f8bf",
   "metadata": {},
   "source": [
    "<b>CROSS VALIDATION<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82918706-10e4-4d3d-a90d-857cb5e55b06",
   "metadata": {},
   "source": [
    " Merge both training and validation sets to perform cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa3853-0653-48c2-99a2-e7936f8d5047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the training and validation sets\n",
    "crossvalid = pd.concat([train_df, valid_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Extract features and labels\n",
    "X_crossvalid = crossvalid['processed_text']  \n",
    "y_crossvalid = crossvalid['category']  \n",
    "\n",
    "# Print the number of rows in the combined dataset\n",
    "print(f\"Number of rows in X_crossvalid: {X_crossvalid.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bb30ad-3646-46ab-bf75-ff0dc8961c24",
   "metadata": {},
   "source": [
    "vectorizing the cross validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ae244-4b18-47ff-8d47-cfbc3590d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,  # Convert all characters to lowercase\n",
    "    stop_words='english',  # Remove English stopwords\n",
    "    max_features=5000  # Consider only the top 5000 words by frequency\n",
    ")\n",
    "\n",
    "# Fit the vectorizer on the combined data and transform the text data into TF-IDF features\n",
    "X_crossvalid_vectorized = vectorizer.fit_transform(X_crossvalid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c197b12-575a-4e27-b488-5ce402ae8969",
   "metadata": {},
   "source": [
    "cross-validation using improved Logistic regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ab477-cb75-497c-8918-cfc466ce3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling \n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_crossvalid_scaled = scaler.fit_transform(X_crossvalid_vectorized)\n",
    "\n",
    "# Initialize the model with GridSearchCV for hyperparameter tuning\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_crossvalid_scaled, y_crossvalid)\n",
    "\n",
    "# Best estimator after hyperparameter tuning\n",
    "log_reg_best = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the cross- validation set\n",
    "\n",
    "y_pred_log_reg_best = log_reg_best.predict(X_crossvalid_scaled)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "print(\"Improved Logistic Regression Performance on Validation Set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_crossvalid, y_pred_log_reg_best)}\")\n",
    "print(classification_report(y_crossvalid, y_pred_log_reg_best))\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm_best = confusion_matrix(y_crossvalid, y_pred_log_reg_best)\n",
    "print(\"Confusion Matrix:\\n\", cm_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa1c7e-b042-469f-8743-20f18dbfea71",
   "metadata": {},
   "source": [
    "The observed faultless performance during cross-validation suggests that the model is most likely being tested on the same data that it was trained on. This leads to overfitting, in which the model memorizes the training data and achieves 100% accuracy on the validation set. This is not a realistic assessment of the model's performance on actually unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d644351e-e8f2-4ded-b9b1-feac5b2b4aa1",
   "metadata": {},
   "source": [
    "Cross-validation using Ensemble Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ace95f-d879-4feb-baff-2cda04e6a5bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Fit LabelEncoder on training data and transform both train and validation data\n",
    "label_encoder = LabelEncoder()\n",
    "y_true_numeric = label_encoder.fit_transform(crossvalid['category'])\n",
    "y_pred_ensemble_crossvalid = ensemble_clf.predict(X_crossvalid_vectorized)\n",
    "\n",
    "# Evaluate the model on the cross-validation set\n",
    "print(\"Ensemble Model Performance on Cross-Validation Set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_true_numeric, y_pred_ensemble_crossvalid)}\")\n",
    "print(classification_report(y_true_numeric, y_pred_ensemble_crossvalid))\n",
    "cm_ensemble_crossvalid = confusion_matrix(y_true_numeric, y_pred_ensemble_crossvalid)\n",
    "print(\"Confusion Matrix on Cross-Validation Set:\\n\", cm_ensemble_crossvalid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eebe596-a936-4a6f-8f51-14fea7b836a8",
   "metadata": {},
   "source": [
    "The ensemble model achieved 93.63% training accuracy but dropped to 76.5% in testing, focusing solely on predicting the majority class (class 1) and missing all instances of class 0. This imbalance skews performance metrics, visible in the confusion matrix. Addressing this issue with adjusted class weights, resampling techniques, or model tuning can improve minority class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee8a9e-c0d2-4e7f-ada2-bb6db543c05e",
   "metadata": {},
   "source": [
    "So far, Our best model is improved Logistic regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b95a1-9d84-4d9f-a214-78b45073d6d6",
   "metadata": {},
   "source": [
    "Appying it to Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d66b92-8924-4739-8426-daded3ea075b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load the test set\n",
    "test_df = pd.read_csv('test.csv')\n",
    "X_test = test_df['processed_text']\n",
    "y_test = test_df['category']\n",
    "\n",
    "# Initialize the vectorizer \n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,  # Convert all characters to lowercase\n",
    "    stop_words='english',  # Remove English stopwords\n",
    "    max_features=5000  # Consider only the top 5000 words by frequency\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "# Transform the test data using the fitted vectorizer and scaler\n",
    "X_test_vectorized = vectorizer.fit_transform(X_test)\n",
    "X_test_scaled = scaler.fit_transform(X_test_vectorized)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_log_reg_best_test = log_reg_best.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"Improved Logistic Regression Performance on Test Set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_log_reg_best_test)}\")\n",
    "print(classification_report(y_test, y_pred_log_reg_best_test))\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm_best_test = confusion_matrix(y_test, y_pred_log_reg_best_test)\n",
    "print(\"Confusion Matrix on Test Set:\\n\", cm_best_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e3f840-bad1-49c7-996e-a1a5053ba18b",
   "metadata": {},
   "source": [
    "This Model when validated with the same data a trained performed flawlessly, but as we evaluated on the unseen independent test set., its performance went down. we will retrain this model with a combined dataset of training and validation data and check for any improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e217eff-6170-42fa-92d9-cca22b3f6773",
   "metadata": {},
   "source": [
    "retraining our improving logistic regression Model with combined train and valid datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80a47c9-d486-4804-af55-69bee9d6a3b6",
   "metadata": {},
   "source": [
    "Applying this re_trained Model to test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5618a74-cf4b-4a1e-afc8-aa50c145a212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the training and validation sets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "valid_df = pd.read_csv('valid.csv')\n",
    "\n",
    "# Combine the training and validation sets for vectorizer fitting\n",
    "full_train_df = pd.concat([train_df, valid_df])\n",
    "X_full_train = full_train_df['processed_text']\n",
    "y_full_train = full_train_df['category']\n",
    "\n",
    "# Initialize the vectorizer \n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,  # Convert all characters to lowercase\n",
    "    stop_words='english',  # Remove English stopwords\n",
    "    max_features=5000  # Consider only the top 5000 words by frequency\n",
    ")\n",
    "\n",
    "# Fit the vectorizer on the combined training data and transform the training data\n",
    "X_full_train_vectorized = vectorizer.fit_transform(X_full_train)\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "# Fit the scaler on the combined training data and transform the training data\n",
    "X_full_train_scaled = scaler.fit_transform(X_full_train_vectorized)\n",
    "\n",
    "# Initialize the model with GridSearchCV for hyperparameter tuning\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_full_train_scaled, y_full_train)\n",
    "\n",
    "# Best estimator after hyperparameter tuning\n",
    "log_reg_best = grid_search.best_estimator_\n",
    "\n",
    "# Train the best model on the full training data\n",
    "log_reg_best.fit(X_full_train_scaled, y_full_train)\n",
    "\n",
    "# Load the test set\n",
    "test_df = pd.read_csv('test.csv')\n",
    "X_test = test_df['processed_text']\n",
    "y_test = test_df['category']\n",
    "\n",
    "# Transform the test data using the fitted vectorizer and scaler\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "X_test_scaled = scaler.transform(X_test_vectorized)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_log_reg_best_test = log_reg_best.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"Improved Logistic Regression Performance on Test Set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_log_reg_best_test)}\")\n",
    "print(classification_report(y_test, y_pred_log_reg_best_test))\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm_best_test = confusion_matrix(y_test, y_pred_log_reg_best_test)\n",
    "print(\"Confusion Matrix on Test Set:\\n\", cm_best_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27238d9-6aea-494a-9190-a1614b214c89",
   "metadata": {},
   "source": [
    "The retraining of the logistic regression model resulted in significant improvements in both accuracy and F1-score. The model's accuracy increased from 71.7% to 92.1%, indicating a substantial enhancement in overall prediction correctness. Moreover, the F1-score improved notably for both classes, particularly for class 0, rising from 13% to 82%. This indicates that the model now performs well not only in correctly classifying instances overall but also in achieving a balanced precision-recall trade-off for both the majority and minority classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747781f5-cb82-4c78-8c58-0f878a1d7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "import joblib\n",
    "joblib.dump(log_reg_best, 'logreg_improved_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b434e6-a76d-4a58-a299-471af70391e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load('logreg_improved_model.pkl') # Verify that the model can be loaded and produce the same results\n",
    "y_pred = log_reg_best.predict(X_test_scaled)\n",
    "loaded_test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Loaded Model Test Set Accuracy:\", loaded_test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
